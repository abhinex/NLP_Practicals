{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f254ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph='''It is important for NLP tasks like sentiment analysis, chatbots and conversation-based AI. \n",
    "It helps machines to understand the speaker's intentions, tone and context which go beyond the literal meaning of words. \n",
    "By identifying sarcasm and emotions this help systems to respond naturally which improves human-computer interaction. \n",
    "By combining these phases NLP systems can effectively interpret, analyze and generate human language making more intelligent and natural interactions between humans and machines.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5de3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999509b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is important for NLP tasks like sentiment analysis, chatbots and conversation-based AI.',\n",
       " \"It helps machines to understand the speaker's intentions, tone and context which go beyond the literal meaning of words.\",\n",
       " 'By identifying sarcasm and emotions this help systems to respond naturally which improves human-computer interaction.',\n",
       " 'By combining these phases NLP systems can effectively interpret, analyze and generate human language making more intelligent and natural interactions between humans and machines.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ec6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/Abhishek/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a82fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('important', 'JJ'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('like', 'IN'), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('chatbots', 'JJ'), ('conversation-based', 'JJ'), ('AI', 'NNP'), ('.', '.')]\n",
      "[('It', 'PRP'), ('helps', 'VBZ'), ('machines', 'NNS'), ('understand', 'VBP'), ('speaker', 'NN'), (\"'s\", 'POS'), ('intentions', 'NNS'), (',', ','), ('tone', 'NN'), ('context', 'NN'), ('go', 'VBP'), ('beyond', 'IN'), ('literal', 'JJ'), ('meaning', 'NN'), ('words', 'NNS'), ('.', '.')]\n",
      "[('By', 'IN'), ('identifying', 'VBG'), ('sarcasm', 'NN'), ('emotions', 'NNS'), ('help', 'VBP'), ('systems', 'NNS'), ('respond', 'VB'), ('naturally', 'RB'), ('improves', 'VBZ'), ('human-computer', 'JJ'), ('interaction', 'NN'), ('.', '.')]\n",
      "[('By', 'IN'), ('combining', 'VBG'), ('phases', 'NNS'), ('NLP', 'NNP'), ('systems', 'NNS'), ('effectively', 'RB'), ('interpret', 'JJ'), (',', ','), ('analyze', 'JJ'), ('generate', 'NN'), ('human', 'JJ'), ('language', 'NN'), ('making', 'VBG'), ('intelligent', 'JJ'), ('natural', 'JJ'), ('interactions', 'NNS'), ('humans', 'NNS'), ('machines', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## pos tagging\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    #sentences[i] = ' '.join(words) # conveting all the Words into sentences\n",
    "    pos_tag=nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd7e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm= Taj mahal is located in Agra\"\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
